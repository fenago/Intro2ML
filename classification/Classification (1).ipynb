{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Data from https://www.kaggle.com/blastchar/telco-customer-churn","metadata":{}},{"cell_type":"markdown","source":"## Notes\n\nThis session covered data obtention and some procedures of data preparation. \n\n**Commands, functions, and methods:** \n\n* `!wget` - Linux shell command for downloading data \n* `pd.read.csv()` - read csv files \n* `df.head()` - take a look of the dataframe \n* `df.head().T` - take a look of the transposed dataframe \n* `df.columns` - retrieve column names of a dataframe \n* `df.columns.str.lower()` - lowercase all the letters \n* `df.columns.str.replace(' ', '_')` - replace the space separator \n* `df.dtypes` - retrieve data types of all series \n* `df.index` - retrive indices of a dataframe\n* `pd.to_numeric()` - convert a series values to numerical values. The `errors=coerce` argument allows making the transformation despite some encountered errors. \n* `df.fillna()` - replace NAs with some value \n* `(df.x == \"yes\").astype(int)` - convert x series of yes-no values to numerical values.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial data preparation","metadata":{}},{"cell_type":"markdown","source":"## Notes\n\nSplitting the dataset with **Scikit-Learn**. \n\n**Classes, functions, and methods:** \n\n* `train_test_split` - Scikit-Learn class for splitting datasets. Linux shell command for downloading data. The `random_state` argument set a random seed for reproducibility purposes.  \n* `df.reset_index(drop=True)` - reset the indices of a dataframe and delete the previous ones. \n* `df.x.values` - extract the values from x series\n* `del df['x']` - delete x series from a dataframe ","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\ndf['TotalCharges'] = df['TotalCharges'].fillna(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns = df.columns.str.lower().str.replace(' ', '_')\n\nstring_columns = list(df.dtypes[df.dtypes == 'object'].index)\n\nfor col in string_columns:\n    df[col] = df[col].str.lower().str.replace(' ', '_')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.churn = (df.churn == 'yes').astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = df_train.churn.values\ny_val = df_val.churn.values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_train['churn']\ndel df_val['churn']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"## Notes\n\nThe EDA for this project consisted of: \n* Checking missing values \n* Looking at the distribution of the target variable (churn)\n* Looking at numerical and categorical variables \n\n**Functions and methods:** \n\n* `df.isnull().sum()` - retunrs the number of null values in the dataframe.  \n* `df.x.value_counts()` returns the number of values for each category in x series. The `normalize=True` argument retrieves the percentage of each category. In this project, the mean of churn is equal to the churn rate obtained with the value_counts method. \n* `round(x, y)` - round an x number with y decimal places\n* `df[x].nunique()` - returns the number of unique values in x series \n","metadata":{}},{"cell_type":"code","source":"df_train_full.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_full.churn.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_mean = df_train_full.churn.mean()\nround(global_mean, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n               'phoneservice', 'multiplelines', 'internetservice',\n               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n               'techsupport', 'streamingtv', 'streamingmovies',\n               'contract', 'paperlessbilling', 'paymentmethod']\nnumerical = ['tenure', 'monthlycharges', 'totalcharges']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_full[categorical].nunique()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature importance","metadata":{}},{"cell_type":"markdown","source":"## Notes\n\n1. **XXX rate:** Difference between mean of the target variable and mean of categories for a feature. If this difference is greater than 0, it means that the category is less likely to be predicted as 1, and if the difference is lower than 0, the group is more likely to churn. The larger differences are indicators that a variable is more important than others.  For instance, this is a Churn use case so this is a measure of the churn rate. \n\n2. **Risk ratio:** Ratio between mean of categories for a feature and mean of the target variable. If this ratio is greater than 1, the category is more likely to churn, and if the ratio is lower than 1, the category is less likely to churn. It expresses the feature importance in relative terms. \n\n**Functions and methods:** \n\n* `df.groupby('x').y.agg([mean()])` - returns a datframe with mean of y series grouped by x series \n* `display(x)` displays an output in the cell of a jupyter notebook. ","metadata":{}},{"cell_type":"code","source":"female_mean = df_train_full[df_train_full.gender == 'female'].churn.mean()\nprint('gender == female:', round(female_mean, 3))\n\nmale_mean = df_train_full[df_train_full.gender == 'male'].churn.mean()\nprint('gender == male:  ', round(male_mean, 3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"female_mean / global_mean","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"male_mean / global_mean","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"partner_yes = df_train_full[df_train_full.partner == 'yes'].churn.mean()\nprint('partner == yes:', round(partner_yes, 3))\n\npartner_no = df_train_full[df_train_full.partner == 'no'].churn.mean()\nprint('partner == no :', round(partner_no, 3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"partner_yes / global_mean","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"partner_no / global_mean","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group = df_train_full.groupby(by='gender').churn.agg(['mean'])\ndf_group['diff'] = df_group['mean'] - global_mean\ndf_group['risk'] = df_group['mean'] / global_mean\ndf_group","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_mean = df_train_full.churn.mean()\nglobal_mean","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in categorical:\n    df_group = df_train_full.groupby(by=col).churn.agg(['mean'])\n    df_group['diff'] = df_group['mean'] - global_mean\n    df_group['risk'] = df_group['mean'] / global_mean\n    display(df_group)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Notes\n\nMutual information is a concept from information theory, which measures how much we can learn about one variable if we know the value of another. In this project, we can think of this as how much do we learn about churn if we have the information from a particular feature. So, it is a measure of the importance of a categorical variable. \n\n**Classes, functions, and methods:** \n\n* `mutual_info_score(x, y)` - Scikit-Learn class for calculating the mutual information between the x target variable and y feature. \n* `df[x].apply(y)` - apply a y function to the x series of the df dataframe. \n* ` df.sort_values(ascending=False).to_frame(name='x')` - sort values in an ascending order and called the column as x. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mutual_info_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_mi(series):\n    return mutual_info_score(series, df_train_full.churn)\n\ndf_mi = df_train_full[categorical].apply(calculate_mi)\ndf_mi = df_mi.sort_values(ascending=False).to_frame(name='MI')\n\n\ndisplay(df_mi.head())\ndisplay(df_mi.tail())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Notes\n\n**Correlation coefficient** measures the degree of dependency between two variables. This value is negative if one variable grows while the other decreases, and it is positive if both variables increase. Depending on its size, the dependency between both variables could be low, moderate, or strong. It allows measuring the importance of numerical variables. \n\n**Functions and methods:** \n\n* `df[x].corrwith(y)` - returns the correlation between x and y series. \n","metadata":{}},{"cell_type":"code","source":"df_train_full[numerical].corrwith(df_train_full.churn).to_frame('correlation')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_full.groupby(by='churn')[numerical].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One-hot encoding","metadata":{}},{"cell_type":"markdown","source":"## Notes\n\nOne-Hot Encoding allows encoding categorical variables in numerical ones. This method represents each category of a variable as one column, and a 1 is assigned if the value belongs to the category or 0 otherwise. \n\n**Classes, functions, and methods:** \n\n* `df[x].to_dict(oriented='records')` - convert x series to dictionaries, oriented by rows. \n* `DictVectorizer().fit_transform(x)` - Scikit-Learn class for converting x dictionaries into a sparse matrix, and in this way doing the one-hot encoding. It does not affect the numerical variables. \n* `DictVectorizer().get_feature_names()` -  returns the names of the columns in the sparse matrix.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction import DictVectorizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dict = df_train[categorical + numerical].to_dict(orient='records')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dict[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dv = DictVectorizer(sparse=False)\ndv.fit(train_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = dv.transform(train_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dv.get_feature_names()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression(solver='liblinear', random_state=1)\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dict = df_val[categorical + numerical].to_dict(orient='records')\nX_val = dv.transform(val_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict_proba(X_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict_proba(X_val)[:, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"churn = y_pred > 0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(y_val == churn).mean()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model interpretation","metadata":{}},{"cell_type":"code","source":"model.intercept_[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict(zip(dv.get_feature_names(), model.coef_[0].round(3)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset = ['contract', 'tenure', 'totalcharges']\ntrain_dict_small = df_train[subset].to_dict(orient='records')\ndv_small = DictVectorizer(sparse=False)\ndv_small.fit(train_dict_small)\n\nX_small_train = dv_small.transform(train_dict_small)\n\ndv_small.get_feature_names()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_small = LogisticRegression(solver='liblinear', random_state=1)\nmodel_small.fit(X_small_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_small.intercept_[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict(zip(dv_small.get_feature_names(), model_small.coef_[0].round(3)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dict_small = df_val[subset].to_dict(orient='records')\nX_small_val = dv_small.transform(val_dict_small)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_small = model_small.predict_proba(X_small_val)[:, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using the model","metadata":{}},{"cell_type":"code","source":"customer = {\n    'customerid': '8879-zkjof',\n    'gender': 'female',\n    'seniorcitizen': 0,\n    'partner': 'no',\n    'dependents': 'no',\n    'tenure': 41,\n    'phoneservice': 'yes',\n    'multiplelines': 'no',\n    'internetservice': 'dsl',\n    'onlinesecurity': 'yes',\n    'onlinebackup': 'no',\n    'deviceprotection': 'yes',\n    'techsupport': 'yes',\n    'streamingtv': 'yes',\n    'streamingmovies': 'yes',\n    'contract': 'one_year',\n    'paperlessbilling': 'yes',\n    'paymentmethod': 'bank_transfer_(automatic)',\n    'monthlycharges': 79.85,\n    'totalcharges': 3320.75,\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = dv.transform([customer])\nmodel.predict_proba(X_test)[0, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(list(X_test[0]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer = {\n    'gender': 'female',\n    'seniorcitizen': 1,\n    'partner': 'no',\n    'dependents': 'no',\n    'phoneservice': 'yes',\n    'multiplelines': 'yes',\n    'internetservice': 'fiber_optic',\n    'onlinesecurity': 'no',\n    'onlinebackup': 'no',\n    'deviceprotection': 'no',\n    'techsupport': 'no',\n    'streamingtv': 'yes',\n    'streamingmovies': 'no',\n    'contract': 'month-to-month',\n    'paperlessbilling': 'yes',\n    'paymentmethod': 'electronic_check',\n    'tenure': 1,\n    'monthlycharges': 85.7,\n    'totalcharges': 85.7\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = dv.transform([customer])\nmodel.predict_proba(X_test)[0, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.14 Explore more\n\nMore things\n\n* Try to exclude least useful features\n\nUse scikit-learn in project of last project\n\n* Re-implement train/val/test split using scikit-learn in the project from the last week\n* Also, instead of our own linear regression, use `LinearRegression` (not regularized) and `RidgeRegression` (regularized). Find the best regularization parameter for Ridge\n* There are other ways to implement one-hot encoding. E.g. using the `OneHotEncoding` class. Check how to use it [here](notebook-scaling-ohe.ipynb).\n* Sometimes numerical features requeire scaling, especially for iterative solves like \"lbfgs\". Check how to use `StandardScaler` for that [here](notebook-scaling-ohe.ipynb).\n\n\nOther projects\n\n* Lead scoring - https://www.kaggle.com/ashydv/leads-dataset\n* Default prediction - https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}