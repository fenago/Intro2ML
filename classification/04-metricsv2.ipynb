{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's train the model again first - to use its results later in this notebook","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.linear_model import LogisticRegression","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\ndf['TotalCharges'] = df['TotalCharges'].fillna(0)\n\ndf.columns = df.columns.str.lower().str.replace(' ', '_')\n\nstring_columns = list(df.dtypes[df.dtypes == 'object'].index)\n\nfor col in string_columns:\n    df[col] = df[col].str.lower().str.replace(' ', '_')\n\ndf.churn = (df.churn == 'yes').astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\ndf_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n\ny_train = df_train.churn.values\ny_val = df_val.churn.values\n\ndel df_train['churn']\ndel df_val['churn']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n               'phoneservice', 'multiplelines', 'internetservice',\n               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n               'techsupport', 'streamingtv', 'streamingmovies',\n               'contract', 'paperlessbilling', 'paymentmethod']\nnumerical = ['tenure', 'monthlycharges', 'totalcharges']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dict = df_train[categorical + numerical].to_dict(orient='records')\n\ndv = DictVectorizer(sparse=False)\ndv.fit(train_dict)\n\nX_train = dv.transform(train_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression(solver='liblinear', random_state=1)\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dict = df_val[categorical + numerical].to_dict(orient='records')\nX_val = dv.transform(val_dict)\ny_pred = model.predict_proba(X_val)[:, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"small_subset = ['contract', 'tenure', 'totalcharges']\ntrain_dict_small = df_train[small_subset].to_dict(orient='records')\ndv_small = DictVectorizer(sparse=False)\ndv_small.fit(train_dict_small)\n\nX_small_train = dv_small.transform(train_dict_small)\n\nmodel_small = LogisticRegression(solver='liblinear', random_state=1)\nmodel_small.fit(X_small_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dict_small = df_val[small_subset].to_dict(orient='records')\nX_small_val = dv_small.transform(val_dict_small)\n\ny_pred_small = model_small.predict_proba(X_small_val)[:, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict_proba(X_val)[:, 1]\nchurn = y_pred >= 0.5\n(churn == y_val).mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_val, y_pred >= 0.5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds = np.linspace(0, 1, 11)\nthresholds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds = np.linspace(0, 1, 21)\n\naccuracies = []\n\nfor t in thresholds:\n    acc = accuracy_score(y_val, y_pred >= t)\n    accuracies.append(acc)\n    print('%0.2f %0.3f' % (t, acc))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\n\nplt.plot(thresholds, accuracies, color='black')\n\nplt.title('Threshold vs Accuracy')\nplt.xlabel('Threshold')\nplt.ylabel('Accuracy')\n\nplt.xticks(np.linspace(0, 1, 11))\n\n# plt.savefig('04_threshold_accuracy.svg')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"churn_small = y_pred_small >= 0.5\n(churn_small == y_val).mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_val, churn_small)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size_val = len(y_val)\nbaseline = np.repeat(False, size_val)\nbaseline","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(baseline, y_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion table","metadata":{}},{"cell_type":"code","source":"true_positive = ((y_pred >= 0.5) & (y_val == 1)).sum()\nfalse_positive = ((y_pred >= 0.5) & (y_val == 0)).sum()\nfalse_negative = ((y_pred < 0.5) & (y_val == 1)).sum()\ntrue_negative = ((y_pred < 0.5) & (y_val == 0)).sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_table = np.array(\n     # predict neg    pos\n    [[true_negative, false_positive], # actual neg\n     [false_negative, true_positive]]) # actual pos\n\nconfusion_table","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_table / confusion_table.sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Precision and recall","metadata":{}},{"cell_type":"code","source":"precision = true_positive / (true_positive + false_positive)\nrecall = true_positive / (true_positive + false_negative)\nprecision, recall","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_table / confusion_table.sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision = true_positive / (true_positive + false_positive)\nrecall = true_positive / (true_positive + false_negative)\nprecision, recall","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC and AUC","metadata":{}},{"cell_type":"markdown","source":"TPR and FPR","metadata":{}},{"cell_type":"code","source":"scores = []\n\nthresholds = np.linspace(0, 1, 101)\n\nfor t in thresholds: #B\n    tp = ((y_pred >= t) & (y_val == 1)).sum()\n    fp = ((y_pred >= t) & (y_val == 0)).sum()\n    fn = ((y_pred < t) & (y_val == 1)).sum()\n    tn = ((y_pred < t) & (y_val == 0)).sum()\n    scores.append((t, tp, fp, fn, tn))\n\ndf_scores = pd.DataFrame(scores)\ndf_scores.columns = ['threshold', 'tp', 'fp', 'fn', 'tn']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scores[::10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\ndf_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scores[::10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\n\nplt.plot(df_scores.threshold, df_scores.tpr, color='black', linestyle='solid', label='TPR')\nplt.plot(df_scores.threshold, df_scores.fpr, color='black', linestyle='dashed', label='FPR')\nplt.legend()\n\nplt.xticks(np.linspace(0, 1, 11))\nplt.yticks(np.linspace(0, 1, 11))\n\nplt.xlabel('Thresholds')\nplt.title('TPR and FPR')\n\n# plt.savefig('04_fpr_tpr_plot.svg')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random baseline","metadata":{}},{"cell_type":"code","source":"def tpr_fpr_dataframe(y_val, y_pred):\n    scores = []\n\n    thresholds = np.linspace(0, 1, 101)\n\n    for t in thresholds:\n        tp = ((y_pred >= t) & (y_val == 1)).sum()\n        fp = ((y_pred >= t) & (y_val == 0)).sum()\n        fn = ((y_pred < t) & (y_val == 1)).sum()\n        tn = ((y_pred < t) & (y_val == 0)).sum()\n\n        scores.append((t, tp, fp, fn, tn))\n\n    df_scores = pd.DataFrame(scores)\n    df_scores.columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n\n    df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n    df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n\n    return df_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1)\ny_rand = np.random.uniform(0, 1, size=len(y_val))\ndf_rand = tpr_fpr_dataframe(y_val, y_rand)\ndf_rand[::10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\n\nplt.plot(df_rand.threshold, df_rand.tpr, color='black', linestyle='solid', label='TPR')\nplt.plot(df_rand.threshold, df_rand.fpr, color='black', linestyle='dashed', label='FPR')\nplt.legend()\n\nplt.xticks(np.linspace(0, 1, 11))\nplt.yticks(np.linspace(0, 1, 11))\n\nplt.xlabel('Thresholds')\nplt.title('TPR and FPR for the random model')\n\n#plt.savefig('04_fpr_tpr_plot_random.svg')\n\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ideal baseline:","metadata":{}},{"cell_type":"code","source":"num_neg = (y_val == 0).sum()\nnum_pos = (y_val == 1).sum()\n\ny_ideal = np.repeat([0, 1], [num_neg, num_pos])\ny_pred_ideal = np.linspace(0, 1, num_neg + num_pos)\n\ndf_ideal = tpr_fpr_dataframe(y_ideal, y_pred_ideal)\ndf_ideal[::10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\n\nplt.plot(df_ideal.threshold, df_ideal.tpr, color='black', linestyle='solid', label='TPR')\nplt.plot(df_ideal.threshold, df_ideal.fpr, color='black', linestyle='dashed', label='FPR')\nplt.legend()\n\nplt.xticks(np.linspace(0, 1, 11))\nplt.yticks(np.linspace(0, 1, 11))\n\nplt.vlines(1 - y_val.mean(), -1, 2, linewidth=0.5, linestyle='dashed', color='grey')\nplt.ylim(-0.03, 1.03)\n\nplt.xlabel('Thresholds')\nplt.title('TPR and FPR for the ideal model')\n\n# plt.savefig('04_fpr_tpr_plot_ideal.svg')\n\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ROC curve","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\n\nplt.plot(df_scores.fpr, df_scores.tpr, color='black', label='Model')\nplt.plot(df_rand.fpr, df_rand.tpr, color='black', lw=1,\n         linestyle='dashed', alpha=0.5, label='Random')\nplt.plot(df_ideal.fpr, df_ideal.tpr, color='black', lw=0.5,\n         linestyle='solid', alpha=0.5, label='Ideal')\n\nplt.legend()\n\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC curve')\n\n# plt.savefig('04_roc_curve_with_baselines.svg')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\n\nplt.plot(df_scores.fpr, df_scores.tpr, color='black')\nplt.plot([0, 1], [0, 1], color='black', lw=0.7, linestyle='dashed', alpha=0.5)\n\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC curve')\n\n# plt.savefig('04_roc_curve.svg')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using Scikit-Learn for plotting the ROC curve","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_val, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\n\nplt.plot(fpr, tpr, color='black')\nplt.plot([0, 1], [0, 1], color='black', lw=0.7, linestyle='dashed', alpha=0.5)\n\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC curve')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AUC: Area under the ROC curve","metadata":{}},{"cell_type":"code","source":"df_scores_small = tpr_fpr_dataframe(y_val, y_pred_small)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc(df_scores.fpr, df_scores.tpr)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc(df_scores_small.fpr, df_scores_small.tpr)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing multiple models with ROC curves","metadata":{}},{"cell_type":"code","source":"fpr_large, tpr_large, _ = roc_curve(y_val, y_pred)\nfpr_small, tpr_small, _ = roc_curve(y_val, y_pred_small)\n\nplt.figure(figsize=(5, 5))\n\nplt.plot(fpr_large, tpr_large, color='black', linestyle='solid', label='Large')\nplt.plot(fpr_small, tpr_small, color='black', linestyle='dashed', label='Small')\nplt.plot([0, 1], [0, 1], color='black', lw=0.7, linestyle='dashed', alpha=0.5)\n\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC curve')\nplt.legend(loc='lower right')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y_val, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y_val, y_pred_small)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpretation of AUC: the probability that a randomly chosen positive example\nranks higher than a randomly chosen negative example","metadata":{}},{"cell_type":"code","source":"neg = y_pred[y_val == 0]\npos = y_pred[y_val == 1]\n\nnp.random.seed(1)\nneg_choice = np.random.randint(low=0, high=len(neg), size=10000)\npos_choice = np.random.randint(low=0, high=len(pos), size=10000)\n(pos[pos_choice] > neg[neg_choice]).mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-fold cross-validation","metadata":{}},{"cell_type":"code","source":"def train(df, y):\n    cat = df[categorical + numerical].to_dict(orient='records')\n    \n    dv = DictVectorizer(sparse=False)\n    dv.fit(cat)\n\n    X = dv.transform(cat)\n\n    model = LogisticRegression(solver='liblinear')\n    model.fit(X, y)\n\n    return dv, model\n\n\ndef predict(df, dv, model):\n    cat = df[categorical + numerical].to_dict(orient='records')\n    \n    X = dv.transform(cat)\n\n    y_pred = model.predict_proba(X)[:, 1]\n\n    return y_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aucs = []\n\nfor train_idx, val_idx in kfold.split(df_train_full):\n    df_train = df_train_full.iloc[train_idx]\n    y_train = df_train.churn.values\n\n    df_val = df_train_full.iloc[val_idx]\n    y_val = df_val.churn.values\n\n    dv, model = train(df_train, y_train)\n    y_pred = predict(df_val, dv, model)\n\n    rocauc = roc_auc_score(y_val, y_pred)\n    aucs.append(rocauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(aucs).round(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('auc = %0.3f ± %0.3f' % (np.mean(aucs), np.std(aucs)))","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tuning the parameter `C`","metadata":{}},{"cell_type":"code","source":"def train(df, y, C=1.0):\n    cat = df[categorical + numerical].to_dict(orient='records')\n    \n    dv = DictVectorizer(sparse=False)\n    dv.fit(cat)\n\n    X = dv.transform(cat)\n\n    model = LogisticRegression(solver='liblinear', C=C)\n    model.fit(X, y)\n\n    return dv, model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfolds = 5\nkfold = KFold(n_splits=nfolds, shuffle=True, random_state=1)\n\nfor C in [0.001, 0.01, 0.1, 0.5, 1, 10]:\n    aucs = []\n\n    for train_idx, val_idx in kfold.split(df_train_full):\n        df_train = df_train_full.iloc[train_idx]\n        df_val = df_train_full.iloc[val_idx]\n\n        y_train = df_train.churn.values\n        y_val = df_val.churn.values\n\n        dv, model = train(df_train, y_train, C=C)\n        y_pred = predict(df_val, dv, model)\n        \n        auc = roc_auc_score(y_val, y_pred)\n        aucs.append(auc)\n\n    print('C=%s, auc = %0.3f ± %0.3f' % (C, np.mean(aucs), np.std(aucs)))","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Full retrain","metadata":{}},{"cell_type":"code","source":"y_train = df_train_full.churn.values\ny_test = df_test.churn.values\n\ndv, model = train(df_train_full, y_train, C=0.5)\ny_pred = predict(df_test, dv, model)\n\nauc = roc_auc_score(y_test, y_pred)\nprint('auc = %.3f' % auc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}